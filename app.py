
import os
import streamlit as st
import psycopg2
import redis
import numpy as np
from utils.text_processing import processar_texto
from langchain_community.chat_models import ChatOpenAI
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from crewai_tools import tool
from redis.commands.search.field import VectorField, TextField
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.query import Query

load_dotenv()

OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

# Conex√£o com o PostgreSQL
def conectar_postgresql():
    try:
        connection = psycopg2.connect(
            host='localhost',
            database='gerdau',
            user='luiz',
            password='CgvQTiyXXEN7xSnsMHBkT5NW2MaxtC',
            port=5432
        )
        print("Conex√£o com o PostgreSQL estabelecida com sucesso.")
        return connection
    except Exception as e:
        st.error(f"Erro ao conectar ao PostgreSQL: {e}")
        st.stop()

def get_table_schema(table_name):
    """Obt√©m o esquema (colunas) de uma tabela espec√≠fica no PostgreSQL."""
    connection = conectar_postgresql()
    cursor = connection.cursor()
    cursor.execute(f"""
        SELECT column_name
        FROM information_schema.columns
        WHERE table_name = '{table_name}' AND table_schema = 'tenant_gerdau_com_br'
    """)
    columns = cursor.fetchall()
    cursor.close()
    connection.close()
    return [column[0] for column in columns]


@tool("Execute multi-table query")
def run_query_multi_table(query: str):
    """Executa uma query SQL envolvendo m√∫ltiplas tabelas."""
    connection = conectar_postgresql()
    cursor = connection.cursor()
    print(f"Executing query: {query}")
    cursor.execute(query)
    result = cursor.fetchall()
    cursor.close()
    connection.close()
    return result


def configurar_agente_sql(chat_history=None):
    daily_report_schema_info = get_table_schema("daily_report")
    project_schema_info = get_table_schema("project")

    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        temperature=0.5,
        model_name="gpt-4o-mini",
    )

    # Inicializar a mem√≥ria apenas uma vez na sess√£o
    if "memory" not in st.session_state:
        st.session_state["memory"] = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    memory = st.session_state["memory"]

    # Atualizar a mem√≥ria com o hist√≥rico de mensagens
    if st.session_state["messages"]:
        for msg in st.session_state["messages"]:
            if msg["role"] == "user":
                memory.chat_memory.add_user_message(msg["content"])
            elif msg["role"] == "assistant":
                memory.chat_memory.add_ai_message(msg["content"])

    sql_developer_agent = Agent(
        role='Postgres analyst senior',
        goal=f"""Responder perguntas relacionadas √†s tabelas 'daily_report' e 'project'. 
        Voc√™ deve usar queries SQL para extrair dados dessas tabelas e combin√°-los, caso necess√°rio.
        As tabelas s√£o relacionadas pela coluna 'project_id' na tabela 'daily_report' e a coluna 'id' na tabela 'project'.
        """,
        backstory = f"""
        Voc√™ √© um analista experiente conectado a um banco de dados que cont√©m a tabela 'tenant_gerdau_com_br.daily_report' e a "tenant_gerdau_com_br.project", com as seguintes colunas: {daily_report_schema_info, project_schema_info}.
        Seu objetivo √© responder perguntas relacionadas a essas tabelas e fornecer informa√ß√µes claras e precisas. Utilize as ferramentas dispon√≠veis para realizar consultas e gerar gr√°ficos, seguindo estas diretrizes:

        1. Tema principal da tabela tenant_gerdau_com_br.daily_report:
        - Relat√≥rios di√°rios de obra, com as seguintes colunas:
            - ID do relat√≥rio (column id)
            - Data de execu√ß√£o (column executed_at)
            - Data de cria√ß√£o (column created_at)
            - ID da obra (column project_id)
            - Data de aprova√ß√£o (column approved_at)
            - N√∫mero sequencial (column sequence)
            - Usu√°rio criador (column user_username)
            - In√≠cio e t√©rmino do almo√ßo (columns lunch_start_time, lunch_end_time)
            - In√≠cio e t√©rmino do expediente (columns work_start_time, work_end_time)
            - Coment√°rios (column comment)
            - Status do relat√≥rio (column status)
            - Nome do empreiteiro (column builder_name)
            - Data de assinatura do empreiteiro (column builder_signed_at)
            - Quantidade de revis√µes (column revision_number)
            - Data de importa√ß√£o (column _import_at)
            - 'approved' = aprovado
            - 'in_review' = em an√°lise
            - 'in_approver' = em aberto

        2. Tema da tabela tenant_gerdau_com_br.project:
            - ID da obra (column id)
            - Data de execu√ß√£o (column executed_at)
            - Data de in√≠cio (column start_at)
            - Data de finaliza√ß√£o (end_at)
            - status da obra (column status)
            - Nome da obra (column name)
            - C√≥digo do contrato (column contract_code)
            - Nome do centro de custo/empresa respns√°vel (column cost_center_name)
            - Data de importa√ß√£o (column _import_at)
            - open = aberto
            - closed = fechado

        3. Respostas baseadas no banco de dados:
        - Utilize ferramentas para consultas ou gera√ß√£o de gr√°ficos somente quando necess√°rio.
        - Ao usar ferramentas, siga rigorosamente este formato:
            - Thought: Explique seu racioc√≠nio.
            - Action: Nome da ferramenta (run_query ou generate_graph).
            - Action Input: Dados no formato JSON.

        4. Perguntas fora do escopo do banco:
        - Responda com seu conhecimento geral, sem mencionar a tabela diretamente.
        - Sempre relembre a fun√ß√£o principal: responder perguntas sobre relat√≥rios di√°rios de obra.

        5. Uso de ferramentas:
        - Nunca reutilize uma ferramenta j√° utilizada na mesma intera√ß√£o.
        - Se n√£o precisar de ferramentas, forne√ßa uma resposta final no formato:
            - Thought: Resuma seu racioc√≠nio.
            - Final Answer: Resposta clara e completa.

        6. Contexto da conversa:
        - Lembre-se de perguntas anteriores para oferecer respostas contextualizadas e coerentes.

        Seu papel √© ser eficiente, preciso e fornecer respostas claras, priorizando consultas no banco de dados relacionadas √† tabela 'tenant_gerdau_com_br.daily_report'.
        """,

        tools=[run_query_multi_table],
        allow_delegation=False,
        verbose=True,
        memory=memory,
        llm=llm
    )

    sql_developer_task = Task(
    description=
    """Responda √† pergunta do usu√°rio ({question}) com base nos dados dispon√≠veis nas tabelas 'daily_report' e 'project', utilizando o contexto da conversa anterior ({chat_history}), se aplic√°vel. Siga estas diretrizes:
    Utilize a rela√ß√£o entre 'daily_report.project_id' e 'project.id' para criar consultas combinadas quando necess√°rio.
    Caso a pergunta n√£o mencione explicitamente as tabelas, inferir com base nas colunas mencionadas.
    
    1. **Consultas ao banco de dados**:
    - Realize uma query apenas se for necess√°rio para responder √† pergunta.
    - Utilize as ferramentas dispon√≠veis (run_query) seguindo o formato padr√£o:
        - Thought: Explique o racioc√≠nio.
        - Action: Nome da ferramenta.
        - Action Input: Entrada no formato JSON.
    - Sempre considere as colunas das tabelas daily_report e project ao construir consultas.

    2. **Perguntas fora do tema do banco**:
    - Se a pergunta n√£o estiver relacionada ao banco de dados, responda com seu conhecimento geral.
    - N√£o utilize ferramentas para perguntas n√£o relacionadas as tabelas daily_report e project.
    - N√£o utilize a ferramenta de gerar gr√°ficos quando a palavra "gr√°fico" n√£o estiver presente na pergunta do usu√°rio.

    3. **Sauda√ß√µes e perguntas gerais**:
    - N√£o use ferramentas para responder sauda√ß√µes ou perguntas gen√©ricas.

    4. **Mem√≥ria e contexto**:
    - Utilize o hist√≥rico da conversa para contexto, mas n√£o para a detec√ß√£o da palavra "gr√°fico".

    5. **Detec√ß√£o da palavra "gr√°fico"**:
    - Verifique se a palavra "gr√°fico" est√° presente **apenas na pergunta atual do usu√°rio ({question})**, sem considerar o hist√≥rico.
    - Defina `option_graph` como `True` somente se a palavra "gr√°fico" estiver presente na pergunta atual.
    - Caso contr√°rio, defina `option_graph` como `False`.

    6. **Respostas**:
    - Se `option_graph` for `False`, responda √† pergunta utilizando dados do banco, mas n√£o gere gr√°ficos.
    - Se `option_graph` for `True`, indique que um gr√°fico ser√° gerado e siga o fluxo apropriado.

    Seu objetivo √© fornecer respostas precisas, claras e √∫teis, priorizando o uso do banco de dados apenas quando necess√°rio.
    Caso a pergunta **contenha explicitamente** a palavra "gr√°fico", fa√ßa uma resposta utilizando os dados encontrados pela query, como se voc√™ estivesse montando um gr√°fico com esses dados, sugira tamb√©m o tipo de gr√°fico que voc√™ prefere na situa√ß√£o.
    """,
    expected_output="""Caso a pergunta seja referente ao banco, preciso de uma resposta que apresente todos os dados obtidos pela query formulando a resposta a partir deles. 
    Caso ocorra uma pergunta que n√£o tenha rela√ß√£o com as tabelas daily_report e project do banco de dados vinculado a voc√™, com exce√ß√£o de sauda√ß√µes, responda com seus conhecimentos gerais e ao fim diga sobre o que o banco de dados se trata e qual a fun√ß√£o que voc√™ exerce dizendo que devem ser feitas perguntas relacionadas a isso para o assunto n√£o se perder. 
    Se voc√™ encontrar a resposta no banco de dados, responda apenas a pergunta de elaborada, sem lembrar sua fun√ß√£o no final.
    A consulta SQL deve incluir as tabelas relevantes. Se ambas forem necess√°rias, a query deve ser um JOIN entre 'daily_report' e 'project'.
    Responda √† pergunta de forma apropriada, seguindo as diretrizes acima.""",
    agent=sql_developer_agent,
    
)

    crew = Crew(
        agents=[sql_developer_agent],
        tasks=[sql_developer_task],
        process=Process.sequential,
        verbose=True
    )

    return crew


# Carregar dados do PostgreSQL
def carregar_dados_postgresql():
    connection = conectar_postgresql()
    cursor = connection.cursor()
    cursor.execute("SELECT * FROM tenant_gerdau_com_br.daily_report")
    textos = " ".join([" ".join(map(str, row)) for row in cursor.fetchall()])
    cursor.close()
    connection.close()
    return textos

# Conex√£o com o Redis
def conectar_redis():
    client =  redis.Redis(host='localhost', port=6379, db=0,)
    print(f'PING FUNCIONOU AQUI {client.ping()}')
    return client

def criar_indice_redis(redis_client):
    idx = redis_client.ft(index_name="idx:embeddings")

    try:
        info = idx.info()
        embedding_dim = info.get("attributes", [{}])[0].get("DIM", None)
        if embedding_dim != 1536:
            print(f"√çndice existente com dimens√£o {embedding_dim}. Apagando e recriando...")
            idx.dropindex(delete_documents=False)
            raise Exception("√çndice recriado devido a dimens√£o incorreta.")
        print("√çndice existente encontrado com dimens√£o correta.")
    except Exception as e:
        print(f"Erro ao verificar ou criar √≠ndice: {e}. Criando um novo √≠ndice...")
        try:
            idx.create_index(
                fields=[
                    VectorField(
                        name="embedding",
                        algorithm="FLAT",
                        attributes={
                            "TYPE": "VECTOR",
                            "DIM": 1536,
                            "DISTANCE_METRIC": "COSINE"
                        }
                    ),
                    TextField("content")
                ],
                definition=IndexDefinition(prefix=["emb:"], index_type=IndexType.HASH)
            )
            print("Novo √≠ndice criado com sucesso.")
        except Exception as e:
            print(f"Erro ao criar √≠ndice no Redis: {e}")



def armazenar_embeddings_redis(redis_client, embeddings, textos):
    for idx, chunk in enumerate(textos):
        # Verificar se o embedding j√° existe no Redis
        if redis_client.exists(f"emb:{idx}"):
            print(f"Embedding emb:{idx} j√° existe, pulando...")
            continue

        # Verificar se o chunk √© v√°lido
        if not chunk.strip():
            print(f"Chunk vazio ou inv√°lido no √≠ndice {idx}, ignorando...")
            continue

        # Gerar o embedding para o novo chunk de texto
        try:
            embedding_vector = embeddings.embed_query(chunk)
        except Exception as e:
            print(f"Erro ao gerar embedding para o chunk {idx}: {e}")
            continue

        # Validar dimens√£o do embedding
        if len(embedding_vector) != 1536:
            print(f"Erro: Dimens√£o do embedding incorreta ({len(embedding_vector)}) no chunk {idx}, esperado 1536.")
            continue

        embedding_vector_bytes = np.array(embedding_vector, dtype=np.float32).tobytes()

        # Armazenar o novo embedding no Redis
        try:
            redis_client.hset(
                f"emb:{idx}",
                mapping={
                    "embedding": embedding_vector_bytes,
                    "content": chunk
                }
            )
            print(f"Novo embedding emb:{idx} armazenado com sucesso.")
        except Exception as e:
            print(f"Erro ao armazenar embedding emb:{idx}: {e}")



def buscar_embeddings_redis(redis_client, embeddings, user_input, k=3):
    try:
        query_vector = embeddings.embed_query(user_input)
        if len(query_vector) != 1536:
            print(f"Erro: Dimens√£o do vetor de consulta incorreta ({len(query_vector)}), esperado 1536.")
            return None

        query_vector_bytes = np.array(query_vector, dtype=np.float32).tobytes()
        search_query = Query(f"*=>[KNN {k} @embedding $vec]").sort_by("content").dialect(2)
        params = {"vec": query_vector_bytes}

        results = redis_client.ft("idx:embeddings").search(search_query, query_params=params)
        if results is None or not hasattr(results, "docs"):
            print("Nenhum resultado encontrado na busca.")
            return None

        print(f"{len(results.docs)} resultados encontrados no Redis.")
        for doc in results.docs:
            print(f"Resultado: {doc.id} - {doc.content[:100]}...")  # Exibe os primeiros 100 caracteres
        return results
    except Exception as e:
        print(f"Erro ao buscar embeddings no Redis: {e}")
        return None


# Main com integra√ß√£o do CrewAI e Redis
def main():
    st.set_page_config(page_title="üí¨ Chat-oppem", page_icon="ü§ñ")
    st.title("OppemBOT ü§ñ")
    st.caption("üöÄ Pergunte para nossa IA especialista da Oppem")

    llm = ChatOpenAI(
        openai_api_key=OPENAI_API_KEY,
        temperature=0.5,
        model_name="gpt-4o-mini",
    )

    # Inicializar mensagens na sess√£o, se ainda n√£o estiverem configuradas
    if "messages" not in st.session_state:
        st.session_state["messages"] = [{"role": "assistant", "content": "Ol√°! Como posso ajudar voc√™ hoje?"}]

    # Exibir todas as mensagens do hist√≥rico na conversa
    for msg in st.session_state["messages"]:
        if msg["role"] == "user":
            st.chat_message("user").write(msg["content"])
        elif msg["role"] == "assistant":
            st.chat_message("assistant").write(msg["content"])

    redis_client = conectar_redis()
    criar_indice_redis(redis_client)

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model="text-embedding-ada-002")

    # Verificar se embeddings est√£o carregados no Redis
    if redis_client.exists("emb:0") == 0:
        textos = carregar_dados_postgresql()
        chunks = processar_texto(textos)
        armazenar_embeddings_redis(redis_client, embeddings, chunks)

    user_input = st.chat_input("Voc√™:")

    if user_input:
        st.session_state["messages"].append({"role": "user", "content": user_input})
        st.chat_message("user").write(user_input)

        # Detec√ß√£o direta da palavra "gr√°fico" na entrada do usu√°rio
        if "gr√°fico" in user_input.lower() or "grafico" in user_input.lower():
            graph_condition = True
        else:
            graph_condition = False

        # Busca no Redis com hist√≥rico
        results = buscar_embeddings_redis(redis_client, embeddings, user_input)

        result = None  # Inicializando result como None

        # Verifique se resultados existem e se a lista de docs n√£o est√° vazia
        if results and hasattr(results, "docs") and len(results.docs) > 0:
            resposta = results.docs[0].content
            st.session_state["messages"].append({"role": "assistant", "content": resposta})
            st.chat_message("assistant").write(resposta)
        else:
            # Mensagem de depura√ß√£o apenas no console, n√£o no chat
            print("Nenhum resultado encontrado no Redis. Tentando buscar no banco de dados...")

            try:
                # Tentando buscar no banco de dados usando o agente
                crew = configurar_agente_sql(chat_history=st.session_state["messages"])
                result = crew.kickoff(inputs={'question': user_input, 'chat_history': st.session_state["messages"]})
                result = vars(result)
            except Exception as e:
                print(f"Erro ao executar o agente: {e}")
                result = None  # Garantir que result seja None caso ocorra erro

            if graph_condition:
                if os.path.exists('graficos/graph.png'):
                    os.remove('graficos/graph.png')
                    
                # Configurar o agente de gr√°ficos
                graph_agent = Agent(
                    role='Graph generator',
                    goal="""Sua fun√ß√£o √© fazer um gr√°fico por meio de c√≥digo e parar a execu√ß√£o quando ele for gerado.
                    ## **ATEN√á√ÉO**
                    - Nunca se esque√ßa de importar a lib os 
                    - Caso o c√≥digo retorne **True**, **encerre a task**
                    - A tool utilizada **deve** esperar um resultado booleano (True ou False)
                    """,
                    backstory="""Voc√™ √© um programador especialista em matplotlib e plotar gr√°ficos por c√≥digo em geral""",
                    allow_code_execution=True,
                    max_execution_time=300,  # 5-minute timeout
                    max_retry_limit=3, # More retries for complex code tasks
                    function_calling_llm="gpt-4o",  # Cheaper model for tool calls
                    verbose=True,
                    llm=llm
                )

                graph_agent_task = Task(
                    description=
                    """Sua tarefa √© fazer um gr√°fico utilizando code e matplotlib para as informa√ß√µes a seguir:
                    {infos}
                    -----
                    Quero que as informa√ß√µes do gr√°fico sejam em portugu√™s-BR, e o dpi da imagem deve ser 90dpi.
                    E neste c√≥digo salve o gr√°fico como png no caminho graficos/graph.png e fa√ßa uma verifica√ß√£o com esse seguinte c√≥digo:
                    
                    ```python
                    import os

                    if os.path.exists(caminho):
                        return True
                    else:
                        return False
                    ```
                    """,
                    expected_output="""√â esperado um gr√°fico com as informa√ß√µes solicitadas, e um valor booleano sinalizando se o gr√°fico foi criado no caminho verificado.""",
                    agent=graph_agent,
                )

                graph_crew = Crew(
                    agents=[graph_agent],
                    tasks=[graph_agent_task],
                    verbose=True
                )


                # Executar o agente para gerar o gr√°fico
                graph_crew.kickoff(inputs={'infos': result.get('raw')})

                graph_result = os.path.exists('graficos/graph.png')

                if graph_result:
                    st.chat_message("assistant").image('graficos/graph.png', caption="Aqui est√° a imagem solicitada!")

            else:
                # Verifique se result foi definido e n√£o √© None antes de tentar acessar
                if result is not None:
                    resposta = result.get("raw")
                    st.session_state["messages"].append({"role": "assistant", "content": resposta})
                    st.chat_message("assistant").write(resposta)
                else:
                    # Mensagem de erro clara somente para o usu√°rio
                    resposta = "Desculpe, n√£o consegui encontrar a resposta no momento."
                    st.session_state["messages"].append({"role": "assistant", "content": resposta})
                    st.chat_message("assistant").write(resposta)




if __name__ == "__main__":
    main()